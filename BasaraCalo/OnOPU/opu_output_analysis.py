# -*- coding: utf-8 -*-
# This code takes as an argument the files generated by opu_mapping.py and outputs a train/test split with the desired
# amount of events and random projections, as well as fits this split on a Ridge and SGD classifier.
# Example of usage:
# python opu_output_analysis.py --type W --inputstub ./opuout/W_AllEvtSparse_100000_random --ncomp 30000 --nevents 30000
# The output are saved in an automatically created repository. The location of this new repository must be changed
# manually if needed.
#TODO: add an argument to only use SGD, or only Ridge, or both

import time
from os.path import exists
import os
import argparse
import datetime

import numpy as np
import pandas as pd


from tqdm import tqdm

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import RidgeCV, SGDClassifier
from joblib import dump

from sklearn.metrics import roc_auc_score


def parse_args():
    parser = argparse.ArgumentParser(
        description="HEP OPU - Model Fitting", formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--type", type=str, default="ttbar", help="Collision type, ttbar or W"
    )
    parser.add_argument(
        "--inputstub", type=str, required=True, help="Path and prefix of the output of the OPU files to be used"
    )
    parser.add_argument(
        "--ncomp", type=int, default=30000, help="Number of random features considered"
    )
    parser.add_argument(
        "--nevents",
        type=int,
        default=24000,
        help="Number of random features considered",
    )
    args = parser.parse_args()

    return args


def hep_analysis(collision_type, inputstub, ncomp, nevents):
    nfiles = 200
    assert nfiles * 900 > nevents, 'Not reading enough files, you must manually change nfiles'
    samples = range(nfiles)
    # samples = random.sample(range(0, 200), nfiles)
    # samples.sort()
    print("Sample considered", samples)

    opu_ls = []
    labels_ls = []

    for i in tqdm(samples):
        outpath = inputstub + f"{i}.npz"
        outfile = np.load(outpath)
        opu_ls.append(outfile["OPU"])
        labels_ls.append(outfile["labels"])

    opu_out = np.vstack(opu_ls).astype(np.int16)
    labels_out = np.vstack(labels_ls)
    print(f"OPU outputs shape {opu_out.shape}.\n" f"Labels shape {labels_out.shape}")

    X = opu_out[:nevents, :ncomp]
    y = np.argmax(labels_out[:nevents], axis=1)
    eQCD, ett, eW = range(3)
    del opu_out, labels_out

    y_sig = y == ett
    y_bkg = y == eQCD
    Xtt = X[y_sig | y_bkg]
    ytt = y[y_sig | y_bkg] > 0
    del X, y

    mean = Xtt.mean(axis=0)
    std = Xtt.std(axis=0)
    Xtt = (Xtt - mean) / std

    tX_train, tX_test, ty_train, ty_test = train_test_split(
        Xtt, ytt, test_size=0.1, stratify=ytt
    )
    del Xtt, ytt

    # Creating a new repository for the experiments. Change the path to this repository if needed.
    current_time = datetime.datetime.now()
    timestr = current_time.strftime("%d%m%Y_%H%M%S")
    exp_path = f"../results/{collision_type}_{nevents}evts_{ncomp}f_{timestr}/"
    os.makedirs(exp_path)
    np.savez(
        exp_path + "traintest.npz",
        X_train=tX_train,
        X_test=tX_test,
        y_train=ty_train,
        y_test=ty_test,
    )

    # log space points between 100 and 100k
    lspace = np.logspace(2, 5, 16)

    joblib_name = exp_path + "joblib_"
    csv_name = exp_path + "reworked_dfscores.txt"
    for idiag in tqdm(range(15)):
        for i in range(len(lspace)):
            for var in lspace[:i]:
                ivar = int(var)
                if ivar > ncomp:
                    ivar = ncomp
                for evt in lspace[:i]:
                    iev = int(evt)
                    if iev > nevents:
                        iev = nevents
                    if iev * ivar > 10 ** idiag:
                        continue
                    # Ridge regression
                    filename = joblib_name + f"Ridge_v{ivar}_e{iev}.joblib"
                    if not exists(filename):
                        X_t, y_t = tX_train[:iev, :ivar], ty_train[:iev]
                        tstart = time.time()
                        gsrW = RidgeCV(alphas=np.logspace(2, 7, num=25))
                        gsrW.fit(X_t, y_t)
                        dump(gsrW, filename)
                        ty_pred = gsrW.predict(tX_test[:, :ivar])
                        tscore = roc_auc_score(ty_test, ty_pred)
                        elapsed = time.time() - tstart
                        print(
                            ivar,
                            iev,
                            "Elapsed time :",
                            elapsed,
                            "alpha",
                            gsrW.alpha_,
                            "score",
                            tscore,
                        )
                        dic = {
                            "nvar": [ivar],
                            "nsamp": [iev],
                            "score": [tscore],
                            "time": [elapsed],
                            "alpha": [gsrW.alpha_],
                            "model": ["ridge"],
                        }
                        # Append csv file
                        dfscore = pd.DataFrame(dic)
                        dfscore.to_csv(csv_name, mode="a", header=False)
                    # SGD
                    filename = joblib_name + f"SGD_v{ivar}_e{iev}.joblib"
                    if not exists(filename):
                        X_t, y_t = tX_train[:iev, :ivar], ty_train[:iev]
                        tstart = time.time()
                        param_grid = {"alpha": np.logspace(-3, 2, num=20)}
                        clh = SGDClassifier(max_iter=100, loss="log")  # .fit(X, y)
                        gsa = GridSearchCV(clh, param_grid=param_grid, n_jobs=-1, cv=3)
                        gsa.fit(X_t, y_t)
                        gsbest = gsa.best_estimator_
                        dump(gsbest, filename)
                        ty_pred = gsbest.predict_proba(tX_test[:, :ivar])[:, 1]
                        tscore = roc_auc_score(ty_test, ty_pred)
                        elapsed = time.time() - tstart
                        print(
                            ivar,
                            iev,
                            "Elapsed time :",
                            elapsed,
                            "alpha",
                            gsbest.alpha,
                            "score",
                            tscore,
                        )
                        dic = {
                            "nvar": [ivar],
                            "nsamp": [iev],
                            "score": [tscore],
                            "time": [elapsed],
                            "alpha": [gsbest.alpha],
                            "model": ["SGD"],
                        }
                        # Append csv file
                        dfscore = pd.DataFrame(dic)
                        dfscore.to_csv(csv_name, mode="a", header=False)


if __name__ == "__main__":
    args = parse_args()
    hep_analysis(args.type, args.inputstub, args.ncomp, args.nevents)
