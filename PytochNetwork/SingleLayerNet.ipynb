{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightonml.projections.sklearn import OPUMap\n",
    "from lightonopu.opu import OPU\n",
    "import time \n",
    "import os\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_random_features = np.load(\"train_random_features.npy\")\n",
    "#test_random_features = np.load(\"test_random_features.npy\")\n",
    "\n",
    "#y_train_bin = np.load(\"labels_train.npy\")\n",
    "#y_test_bin = np.load(\"labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features_tofloat = torch.from_numpy(train_random_features).float()\n",
    "#train_label_tofloat = torch.from_numpy(y_train_bin).float()\n",
    "\n",
    "#test_features_tofloat = torch.from_numpy(test_random_features).float()\n",
    "#test_label_tofloat = torch.from_numpy(y_test_bin).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images_to_use = 4096\n",
    "number_of_features_to_use = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = h5py.File(\"../RandomFeatures/3bits4binstrain.h5\", 'r')\n",
    "\n",
    "train_random_features = f_train['inputs'][:number_of_images_to_use,:number_of_features_to_use]\n",
    "y_train_bin = f_train['labels'][:number_of_images_to_use]\n",
    "weights_train = f_train['weights'][:number_of_images_to_use]\n",
    "\n",
    "f_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = h5py.File(\"../RandomFeatures/3bits4bintest.h5\",'r')\n",
    "\n",
    "test_random_features = f_test['inputs'][:,:number_of_features_to_use]\n",
    "y_test_bin = f_test['labels'][:]\n",
    "weights_test = f_test['weights'][:]\n",
    "\n",
    "f_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_raw = h5py.File(\"../Data/train.h5\", 'r')\n",
    "f_test_raw = h5py.File(\"../Data/test.h5\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "passSR_train = f_train_raw['all_events']['passSR'][:number_of_images_to_use]\n",
    "passSR_test = f_test_raw['all_events']['passSR'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137471, 1600)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_random_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random_features = np.sqrt(train_random_features)\n",
    "test_random_features = np.sqrt(test_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max = preprocessing.MinMaxScaler()\n",
    "min_max.fit(train_random_features[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59f427caaa44a3aa3eee5468e4bf712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4096), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(train_random_features.shape[0])):\n",
    "    train_random_features[i] = min_max.transform(train_random_features[i:i+1])\n",
    "#train_random_features = min_max.transform(train_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137f310d89e34904b213266afddb032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=137471), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(test_random_features.shape[0])):\n",
    "    test_random_features[i] = min_max.transform(test_random_features[i:i+1])\n",
    "#test_random_features = min_max.transform(test_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_random_features = np.sqrt(train_random_features)\n",
    "#test_random_features = np.sqrt(test_random_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "dataset_train = TensorDataset( torch.Tensor(train_random_features), torch.Tensor(y_train_bin),torch.tensor(weights_train))\n",
    "data_loader_train = DataLoader(dataset_train,batch_size=batch_size,shuffle=True)\n",
    "#data_loader_test = DataLoader((test_random_features,test_label_tofloat),batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(train_random_features.shape[1], 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1c75bf550f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: max(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "max_weight = torch.max(weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.6978286504745483\n",
      "epoch 2, loss 0.6574543118476868\n",
      "epoch 3, loss 0.6356613039970398\n",
      "epoch 4, loss 0.6314623355865479\n",
      "epoch 5, loss 0.5842288732528687\n",
      "epoch 6, loss 0.5759412050247192\n",
      "epoch 7, loss 0.5432484149932861\n",
      "epoch 8, loss 0.5800410509109497\n",
      "epoch 9, loss 0.5170411467552185\n",
      "epoch 10, loss 0.4774196743965149\n",
      "epoch 11, loss 0.4913025498390198\n",
      "epoch 12, loss 0.4632573425769806\n",
      "epoch 13, loss 0.46513351798057556\n",
      "epoch 14, loss 0.42309701442718506\n",
      "epoch 15, loss 0.4065735936164856\n",
      "epoch 16, loss 0.4417531192302704\n",
      "epoch 17, loss 0.39135676622390747\n",
      "epoch 18, loss 0.4088679850101471\n",
      "epoch 19, loss 0.3863059878349304\n",
      "epoch 20, loss 0.37081378698349\n",
      "epoch 21, loss 0.35271477699279785\n",
      "epoch 22, loss 0.320900559425354\n",
      "epoch 23, loss 0.3410792946815491\n",
      "epoch 24, loss 0.336629182100296\n",
      "epoch 25, loss 0.3130284547805786\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay = .1,amsgrad=True)\n",
    "model.train()\n",
    "\n",
    "for num_epochs in range(25):\n",
    "    counter = 0\n",
    "    for inp, lbl,weight in data_loader_train:\n",
    "        #print(torch.max(weight))\n",
    "        logits = model.forward(inp)\n",
    "        loss = criterion(logits.reshape(logits.shape[0]), lbl)\n",
    "        loss =(loss * torch.log(weight.float()+1)/(torch.log(weight.float()+1).sum())).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(counter%10 == 0):\n",
    "            print('epoch {}, loss {}'.format(num_epochs+1, loss.item()))\n",
    "        counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_output = []\n",
    "for i in tqdm(range(test_random_features.shape[0])):\n",
    "    y_output.append(np.array(model(torch.Tensor(test_random_features[i:i+1])).detach()[0]))\n",
    "    \n",
    "test_output_sgd = np.array(y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passSR_test.shape)\n",
    "test_output_sgd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.add(test_output_sgd,passSR_test.reshape(-1,1),test_output_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_opu, tpr_opu, thresholds = metrics.roc_curve(y_test_bin,test_output_sgd,sample_weight=weights_test)\n",
    "metrics.auc(fpr_opu, tpr_opu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dot = np.sum(weights_test[(passSR_test == 1) & (y_test_bin == 0)]) / np.sum(weights_test[y_test_bin==0])\n",
    "y_dot = np.sum(weights_test[(passSR_test == 1) & (y_test_bin == 1)]) / np.sum(weights_test[y_test_bin==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyplot.scatter(x_dot, y_dot,label=\"Physics selection\")\n",
    "pyplot.plot(fpr_opu, tpr_opu, lw=2,alpha=.6,label=\"opu\",color='red')\n",
    "pyplot.axis((0,.001,0,1))\n",
    "pyplot.xlabel(\"fpr\")\n",
    "pyplot.ylabel(\"tpr\")\n",
    "pyplot.title(\"using 16000 OPU Features on entire data\")\n",
    "pyplot.legend(loc='upper right')\n",
    "#pyplot.savefig(\"../Results/SHIFTED_OPUOnImages_final_thesis_result_16000_feaures_zoomed_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../Results/BDT_24th_feature_test\",test_output_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "\n",
    "for i in range(train_random_features.shape[0]):\n",
    "    train_scores.append(np.array(model(torch.Tensor(train_random_features[i:i+1])).detach()[0]))\n",
    "    #print(train_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../Results/BDT_24th_feature_train\",np.array(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_opu_train, tpr_opu_train, thresholds = metrics.roc_curve(y_train_bin,train_scores,sample_weight=weights_train)\n",
    "metrics.auc(fpr_opu_train, tpr_opu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMax = preprocessing.MinMaxScaler()\n",
    "minMax.fit(train_scores)\n",
    "train_scores = minMax.transform(train_scores)\n",
    "#test_scores = np.array(y_output)\n",
    "test_output_sgd = minMax.transform(test_output_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_train_test(y_pred_train, y_train, y_pred, y_test, high_low=(0,1), bins=30):\n",
    "    pyplot.hist(y_pred_train[y_train == 1],\n",
    "                 color='r', alpha=0.5, range=high_low, bins=bins,\n",
    "                 histtype='stepfilled', density=True,\n",
    "                 label='S (train)') # alpha is transparancy\n",
    "    pyplot.hist(y_pred_train[y_train == 0],\n",
    "                 color='b', alpha=0.5, range=high_low, bins=bins,\n",
    "                 histtype='stepfilled', density=True,\n",
    "                 label='B (train)')\n",
    "\n",
    "    hist, bins = np.histogram(y_pred[y_test == 1], bins=bins, range=high_low, \n",
    "                                   density=True)\n",
    "    scale = len(y_pred[y_test == 1]) / sum(hist)\n",
    "    err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "    #width = (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    pyplot.errorbar(center, hist, yerr=err, fmt='o', c='r', label='S (test)')\n",
    "\n",
    "    hist, bins = np.histogram(y_pred[y_test == 0],\n",
    "                                  bins=bins, range=high_low, density=True)\n",
    "    scale = len(y_pred[y_test == 0]) / sum(hist)\n",
    "    err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "    #width = (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    pyplot.errorbar(center, hist, yerr=err, fmt='o', c='b', label='B (test)')\n",
    "    pyplot.xlabel(\"Scores\")\n",
    "    pyplot.ylabel(\"Arbitrary units\")\n",
    "    pyplot.legend(loc='best')\n",
    "    \n",
    "    pyplot.savefig(\"../Results/scores_plot_FINAL_THESIS_RESULT_16000_Features_3BITS4BINS_LOGofWEIGHT_SMALL-TESTSET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_train_test(np.array(train_scores),y_train_bin,test_output_sgd,y_test_bin,(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29c35bd7bb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"OPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fpr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tpr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (LightOn OPU)",
   "language": "python",
   "name": "lighton_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
