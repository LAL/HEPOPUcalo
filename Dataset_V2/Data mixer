# This code takes the datasets qcd, ttbar and W (sorted by type of reaction) provided by the database of the CERN and
# create a bunch of mixed datas that can be used by TransformArrowSparseFloat code.

def Melanger(Chemin,qcd,ttbar,W): #Chemin(str) is the path to the directory where the files with the mixed datas
    #will be and qcd,ttbar and W are the paths where datas are (sorted by reaction type)
    
    HLF=[]
    Labels=[]
    Particles=[]
    
    fichiers_h5_qcd = os.listdir(qcd)
    fichiers_h5_ttbar = os.listdir(ttbar)
    fichiers_h5_W = os.listdir(W)
    
    Nb_qcd= len(fichiers_h5_qcd)
    Nb_ttbar= len(fichiers_h5_ttbar)
    Nb_W= len(fichiers_h5_W)
    
    Counter_qcd=0
    Counter_ttbar=0
    Counter_W=0
    
    Au_debut_qcd = True
    Au_debut_ttbar = True
    Au_debut_W = True
    
    Iterateur_decoupage=0
    Iterateur_nom=0
    
    while Counter_qcd <= Nb_qcd or Counter_ttbar <= Nb_ttbar or Counter_W <= Nb_W:
        
        if Iterateur_decoupage <= 100: # able the cutting in many datasets
            
            print(Iterateur_decoupage)
            
            Iterateur_decoupage=Iterateur_decoupage+1
            Choix =random.random() # repertories are choosen randomly
            print(Choix)
        
            if Choix <= 1/3 : #qcd was choosen
            
                if Au_debut_qcd: # able the initialisation
                
                    minicounter_qcd=0
                
                    Un_fichier_qcd = h5py.File(qcd + "//" + fichiers_h5_qcd[Counter_qcd], "r")
                
                    datasetHLF_qcd = Un_fichier_qcd['HLF']
                    datasetParticles_qcd = Un_fichier_qcd['Particles']
                
                    HLF.append(datasetHLF_qcd[0])
                    Labels.append([1,0,0])
                    Particles.append(datasetParticles_qcd[0])
                
                    Au_debut_qcd=False
                
                    minicounter_qcd = minicounter_qcd+1
            
                else: #the cursor is in the middle of the files...
                
                    if minicounter_qcd < len(datasetParticles_qcd): #... but not at the end
                
                        HLF.append(datasetHLF_qcd[minicounter_qcd])
                        Labels.append([1,0,0])
                        Particles.append(datasetParticles_qcd[minicounter_qcd])
                    
                        minicounter_qcd = minicounter_qcd+1
                
                    else: # when the cursor is at the end, the current file is closed and the next one is opened...
                    
                        Un_fichier_qcd.close()
                        Counter_qcd= Counter_qcd+1
                    
                        if Counter_qcd < Nb_qcd: # ...if there are always files
                    
                            minicounter_qcd=0
                
                            Un_fichier_qcd = h5py.File(qcd + "//" + fichiers_h5_qcd[Counter_qcd], "r")
                
                            datasetHLF_qcd = Un_fichier_qcd['HLF']
                            datasetParticles_qcd = Un_fichier_qcd['Particles']
                
                            HLF.append(datasetHLF_qcd[0])
                            Labels.append([1,0,0])
                            Particles.append(datasetParticles_qcd[0])
                    
                            minicounter_qcd = minicounter_qcd+1
        
            elif Choix >= 1/3: #ttbar
            
                if Au_debut_ttbar:
                
                    minicounter_ttbar=0
                
                    Un_fichier_ttbar = h5py.File(ttbar + "//" + fichiers_h5_ttbar[Counter_ttbar], "r")
                
                    datasetHLF_ttbar = Un_fichier_ttbar['HLF']
                    datasetParticles_ttbar = Un_fichier_ttbar['Particles']
                
                    HLF.append(datasetHLF_ttbar[0])
                    Labels.append([0,1,0])
                    Particles.append(datasetParticles_ttbar[0])
                
                    Au_debut_ttbar=False
                
                    minicounter_ttbar = minicounter_ttbar+1
            
                else:
                
                    if minicounter_ttbar < len(datasetParticles_ttbar):
                
                        HLF.append(datasetHLF_ttbar[minicounter_ttbar])
                        Labels.append([0,1,0])
                        Particles.append(datasetParticles_ttbar[minicounter_ttbar])
                    
                        minicounter_ttbar = minicounter_ttbar+1
                
                    else:
                    
                        Un_fichier_ttbar.close()
                        Counter_ttbar= Counter_ttbar+1
                    
                        if Counter_ttbar < Nb_ttbar:
                    
                            minicounter_ttbar=0
                
                            Un_fichier_ttbar = h5py.File(ttbar + "//" + fichiers_h5_ttbar[Counter_ttbar], "r")
                
                            datasetHLF_ttbar = Un_fichier_ttbar['HLF']
                            datasetParticles_ttbar = Un_fichier_ttbar['Particles']

                            HLF.append(datasetHLF_ttbar[0])
                            Labels.append([0,1,0])
                            Particles.append(datasetParticles_ttbar[0])
                    
                            minicounter_ttbar = minicounter_ttbar+1
        
            else: #W
            
                if Au_debut_W:
                
                    minicounter_W=0
                
                    Un_fichier_W = h5py.File(W + "//" + fichiers_h5_W[Counter_W], "r")
                
                    datasetHLF_W = Un_fichier_W['HLF']
                    datasetParticles_W = Un_fichier_W['Particles']
                
                    HLF.append(datasetHLF_W[0])
                    Labels.append([0,0,1])
                    Particles.append(datasetParticles_W[0])
                
                    Au_debut_W=False
                
                    minicounter_W = minicounter_W+1
            
                else:
                
                    if minicounter_W < len(datasetParticles_W):
                
                        HLF.append(datasetHLF_W[minicounter_W])
                        Labels.append([0,0,1])
                        Particles.append(datasetParticles_W[minicounter_W])
                    
                        minicounter_W = minicounter_W+1
                
                    else:
                    
                        Un_fichier_W.close()
                        Counter_W= Counter_W+1
                    
                        if Counter_W < Nb_W:
                    
                            minicounter_W=0
                
                            Un_fichier_W = h5py.File(W + "//" + fichiers_h5_W[Counter_W], "r")
                
                            datasetHLF_W = Un_fichier_W['HLF']
                            datasetParticles_W = Un_fichier_W['Particles']
                
                            HLF.append(datasetHLF_W[0])
                            Labels.append([0,0,1])
                            Particles.append(datasetParticles_W[0])
                    
                            minicounter_W = minicounter_W+1
        else:
        
            donnees_melangees = h5py.File(Chemin+'//'+'mixed_data_'+str(Iterateur_nom)+'.h5', 'a') #a h5py file is created
            #with mixed datas
            
            HLF=HLF[:][1:] # removing the Event ID column
            Particles=Particles[:][:][1:]
    
            HLF = donnees_melangees.create_dataset(name='HLF', data=np.array(HLF), dtype="f8")
            Labels = donnees_melangees.create_dataset(name='Labels', data=np.array(Labels), dtype="f8")
            Particles = donnees_melangees.create_dataset(name='Particles', data=np.array(Particles), dtype="f8")
    
            donnees_melangees.close()
        
            HLF=[]
            Labels=[]
            Particles=[]
        
            Iterateur_decoupage=0
            Iterateur_nom=Iterateur_nom+1
            
